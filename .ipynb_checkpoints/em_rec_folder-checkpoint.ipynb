{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.datasets import get_labels\n",
    "from utils.inference import load_image\n",
    "from utils.preprocessor import preprocess_input\n",
    "emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "emotion_labels = get_labels('fer2013')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# hyper-parameters for bounding boxes shape\n",
    "emotion_offsets = (20, 40)\n",
    "emotion_offsets = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 62, 62, 8)     72          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 62, 62, 8)     32          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 62, 62, 8)     0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 60, 60, 8)     576         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 60, 60, 8)     32          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 60, 60, 8)     0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCon (None, 60, 60, 16)    200         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 60, 60, 16)    64          separable_conv2d_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 60, 60, 16)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCon (None, 60, 60, 16)    400         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 60, 60, 16)    64          separable_conv2d_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 30, 30, 16)    128         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 30, 30, 16)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 30, 30, 16)    64          conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 30, 30, 16)    0           max_pooling2d_1[0][0]            \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCon (None, 30, 30, 32)    656         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 30, 30, 32)    128         separable_conv2d_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 30, 30, 32)    0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCon (None, 30, 30, 32)    1312        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 30, 30, 32)    128         separable_conv2d_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 15, 15, 32)    512         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 15, 15, 32)    0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 15, 15, 32)    128         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 15, 15, 32)    0           max_pooling2d_2[0][0]            \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCon (None, 15, 15, 64)    2336        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 15, 15, 64)    256         separable_conv2d_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 15, 15, 64)    0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCon (None, 15, 15, 64)    4672        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 15, 15, 64)    256         separable_conv2d_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 8, 8, 64)      2048        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 8, 8, 64)      0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 8, 8, 64)      256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 8, 8, 64)      0           max_pooling2d_3[0][0]            \n",
      "                                                                   batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCon (None, 8, 8, 128)     8768        add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 8, 8, 128)     512         separable_conv2d_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 8, 8, 128)     0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCon (None, 8, 8, 128)     17536       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 8, 8, 128)     512         separable_conv2d_8[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 4, 4, 128)     8192        add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 4, 4, 128)     0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 4, 4, 128)     512         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 4, 4, 128)     0           max_pooling2d_4[0][0]            \n",
      "                                                                   batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 4, 4, 7)       8071        add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 7)             0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Activation)         (None, 7)             0           global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f1dab1f6b00>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size=l_model('prob')\n",
    "emotion_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_model(layer_label):\n",
    "    # loading modelsf\n",
    "    emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "    # getting input model shapes for inference\n",
    "    emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "    if layer_label=='emb':\n",
    "        emotion_classifier.layers.pop()\n",
    "        emotion_classifier.layers.pop()\n",
    "        emotion_classifier.outputs = [emotion_classifier.layers[-1].output]\n",
    "        emotion_classifier.layers[-1].outbound_nodes = []\n",
    "#     emotion_classifier.summary()\n",
    "    return emotion_classifier, emotion_target_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process list of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64  errors in 9400 faces\n"
     ]
    }
   ],
   "source": [
    "path_train_negatives = '../imgs/train_crops/positive/*.bmp'\n",
    "negative_faces = glob.glob(path_train_negatives)\n",
    "fully = False\n",
    "i=0\n",
    "j=0\n",
    "for image_path in negative_faces:\n",
    "    try:\n",
    "        gray_image = load_image(image_path, grayscale=True)\n",
    "    except:\n",
    "        j=j+1\n",
    "        continue\n",
    "    gray_image = np.squeeze(gray_image)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    gray_face = gray_image\n",
    "    \n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "    \n",
    "    try:\n",
    "        gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "    except:\n",
    "        print('exception ignored')\n",
    "        \n",
    "    gray_face = preprocess_input(gray_face, True)\n",
    "    gray_face = np.expand_dims(gray_face, 0)\n",
    "    gray_face = np.expand_dims(gray_face, -1)\n",
    "    \n",
    "    \n",
    "    i=i+1\n",
    "print(j,' errors in', len(negative_faces),'faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f1da82bfeb8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_emb():\n",
    "    emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "    emotion_labels = get_labels('fer2013')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # hyper-parameters for bounding boxes shape\n",
    "    emotion_offsets = (20, 40)\n",
    "    emotion_offsets = (0, 0)\n",
    "\n",
    "    # loading modelsf\n",
    "    emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "    # getting input model shapes for inference\n",
    "    emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "    emotion_classifier.layers.pop()\n",
    "    emotion_classifier.layers.pop()\n",
    "    emotion_classifier.outputs = [emotion_classifier.layers[-1].output]\n",
    "    emotion_classifier.layers[-1].outbound_nodes = []\n",
    "    emotion_classifier.summary()\n",
    "    return emotion_classifier, emotion_target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process faces (pre-last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dict_faces(input_path, layer_label):\n",
    "    emotion_classifier,emotion_target_size = l_model(layer_label)\n",
    "    path_train_negatives = input_path\n",
    "    negative_faces = glob.glob(path_train_negatives)\n",
    "    fully = False\n",
    "    i=0\n",
    "    j=0\n",
    "    dict_faces={}\n",
    "    for image_path in negative_faces:\n",
    "        percentage=i/len(negative_faces)*100\n",
    "        try:\n",
    "            gray_image = load_image(image_path, grayscale=True)\n",
    "        except:\n",
    "            j=j+1\n",
    "            continue\n",
    "        gray_image = np.squeeze(gray_image)\n",
    "        gray_image = gray_image.astype('uint8')\n",
    "\n",
    "        gray_face = gray_image\n",
    "\n",
    "        gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except:\n",
    "            print('exception ignored')\n",
    "\n",
    "        gray_face = preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        gray_face = np.expand_dims(gray_face, -1)\n",
    "        dict_faces[str(image_path)]=emotion_classifier.predict(gray_face)\n",
    "    #     print(dict_faces)\n",
    "    #     with open('negative.txt', 'a') as file:\n",
    "    #         file.write(str(image_path) + ' ')\n",
    "    #         for prob in emotion_classifier.predict(gray_face)[0]:\n",
    "    #             file.write( str(prob) + ' ')\n",
    "    #         file.write('\\n')\n",
    "        i=i+1\n",
    "        sys.stdout.write(\"\\r%d%%\" % percentage)\n",
    "        sys.stdout.flush()\n",
    "    #     print(i)\n",
    "    print(j,' errors in', len(negative_faces),'faces')\n",
    "    return dict_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_faces_to_file(em_label, layer_label, val_or_train):\n",
    "    f_name=em_label+'_'+layer_label+'_'+val_or_train\n",
    "    file=open(f_name, 'wb')\n",
    "    pickle.dump(get_dict_faces('../imgs/'+val_or_train+'_crops/'+em_label+'/*', layer_label),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_dict_faces():\n",
    "    layer_label='prob'\n",
    "    val_or_train = 'train'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)\n",
    "    val_or_train = 'val'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)\n",
    "    layer_label='emb'\n",
    "    val_or_train = 'train'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)\n",
    "    val_or_train = 'val'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%139  errors in 15401 faces\n",
      "99%64  errors in 9400 faces\n",
      "99%70  errors in 10046 faces\n",
      "99%69  errors in 8197 faces\n",
      "99%48  errors in 4995 faces\n",
      "99%51  errors in 6013 faces\n",
      "99%139  errors in 15401 faces\n",
      "99%64  errors in 9400 faces\n",
      "99%70  errors in 10046 faces\n",
      "99%69  errors in 8197 faces\n",
      "99%48  errors in 4995 faces\n",
      "99%51  errors in 6013 faces\n"
     ]
    }
   ],
   "source": [
    "save_all_dict_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('negative_pre_last_val.txt', 'wb')\n",
    "pickle.dump(dict_faces,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
