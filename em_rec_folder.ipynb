{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.datasets import get_labels\n",
    "from utils.inference import load_image\n",
    "from utils.preprocessor import preprocess_input\n",
    "emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "emotion_labels = get_labels('fer2013')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# hyper-parameters for bounding boxes shape\n",
    "emotion_offsets = (20, 40)\n",
    "emotion_offsets = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f308658ac8dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memotion_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_target_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memotion_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l_model' is not defined"
     ]
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size=l_model('prob')\n",
    "emotion_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_model(layer_label):\n",
    "    # loading modelsf\n",
    "    filepath='../../FacialExpressionRecognition/MPM5.hdf5'\n",
    "    emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "    emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "    # getting input model shapes for inference\n",
    "    \n",
    "#     emotion_classifier.summary()\n",
    "    if 'fer' in layer_label:\n",
    "        emotion_classifier=model_generate()\n",
    "        emotion_classifier.load_weights(filepath)\n",
    "        emotion_target_size=(48,48)\n",
    "    if 'emb' in layer_label:\n",
    "        emotion_classifier.layers.pop()\n",
    "        emotion_classifier.layers.pop()\n",
    "        emotion_classifier.outputs = [emotion_classifier.layers[-1].output]\n",
    "        emotion_classifier.layers[-1].outbound_nodes = []\n",
    "    \n",
    "    return emotion_classifier, emotion_target_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process list of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_negatives = '../imgs/train_crops/positive/*.bmp'\n",
    "negative_faces = glob.glob(path_train_negatives)\n",
    "fully = False\n",
    "i=0\n",
    "j=0\n",
    "for image_path in negative_faces:\n",
    "    try:\n",
    "        gray_image = load_image(image_path, grayscale=True)\n",
    "    except:\n",
    "        j=j+1\n",
    "        continue\n",
    "    gray_image = np.squeeze(gray_image)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    gray_face = gray_image\n",
    "    \n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "    \n",
    "    try:\n",
    "        gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "    except:\n",
    "        print('exception ignored')\n",
    "        \n",
    "    gray_face = preprocess_input(gray_face, True)\n",
    "    gray_face = np.expand_dims(gray_face, 0)\n",
    "    gray_face = np.expand_dims(gray_face, -1)\n",
    "    \n",
    "    \n",
    "    i=i+1\n",
    "print(j,' errors in', len(negative_faces),'faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import numpy\n",
    "import cv2\n",
    "import scipy\n",
    "import csv\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "def model_generate():\n",
    "\tfilepath='../../FacialExpressionRecognition/MPM5.hdf5'\n",
    "\timg_rows, img_cols = 48, 48\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(64, 5, 5, border_mode='valid',\n",
    "\t\t\t\t\t\t\tinput_shape=(1, img_rows, img_cols)))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(2, 2), dim_ordering='th'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(5, 5),strides=(2, 2)))\n",
    "\t  \n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')) \n",
    "\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th')) \n",
    "\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "\t \n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th'))\n",
    "\tmodel.add(Convolution2D(128, 3, 3))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th'))\n",
    "\tmodel.add(Convolution2D(128, 3, 3))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\n",
    "\tmodel.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='th'))\n",
    "\tmodel.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "\t \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\t \n",
    "\tmodel.add(Dense(7))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\tada = Adadelta(lr=0.1, rho=0.95, epsilon=1e-08)\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\t  optimizer=ada,\n",
    "\t\t\t\t  metrics=['accuracy'])\n",
    "# \tmodel.load_weights(filepath)\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.5/site-packages/keras/models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"valid\", input_shape=(1, 48, 48...)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(2, 2), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_first\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 44, 44)        1664      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 64, 44, 44)        123904    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 64, 48, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 64, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 22, 22)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 64, 22, 22)        30976     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 64, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 22, 22)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 64, 22, 22)        30976     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 128, 10, 10)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 128, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 10, 10)       147584    \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 128, 10, 10)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 128, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 128, 5, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              3277824   \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "p_re_lu_7 (PReLU)            (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 4,837,888\n",
      "Trainable params: 4,837,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size = l_model('fer_emb')\n",
    "emotion_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_target_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_emb():\n",
    "    emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "    emotion_labels = get_labels('fer2013')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # hyper-parameters for bounding boxes shape\n",
    "    emotion_offsets = (20, 40)\n",
    "    emotion_offsets = (0, 0)\n",
    "\n",
    "    # loading modelsf\n",
    "    emotion_classifier = load_model(emotion_model_path)\n",
    "\n",
    "    # getting input model shapes for inference\n",
    "    emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "    emotion_classifier.layers.pop()\n",
    "    emotion_classifier.layers.pop()\n",
    "    emotion_classifier.outputs = [emotion_classifier.layers[-1].output]\n",
    "    emotion_classifier.layers[-1].outbound_nodes = []\n",
    "    emotion_classifier.summary()\n",
    "    return emotion_classifier, emotion_target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 62, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 62, 62, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 62, 62, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 8)    576         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 60, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 60, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 60, 60, 16)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 60, 60, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 60, 60, 16)   400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 16)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 30, 30, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 30, 30, 32)   1312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 15, 15, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 15, 15, 64)   4672        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 8, 8, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 8, 8, 128)    17536       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 7)      8071        add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.5/site-packages/keras/models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "cl=load_model_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process faces (pre-last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dict_faces(input_path, layer_label):\n",
    "    emotion_classifier,emotion_target_size = l_model(layer_label)\n",
    "    path_train_negatives = input_path\n",
    "    negative_faces = glob.glob(path_train_negatives)\n",
    "    fully = False\n",
    "    i=0\n",
    "    j=0\n",
    "    dict_faces={}\n",
    "    \n",
    "    for image_path in negative_faces:\n",
    "        percentage=i/len(negative_faces)*100\n",
    "        try:\n",
    "            gray_image = load_image(image_path, grayscale=True)\n",
    "        except:\n",
    "            j=j+1\n",
    "            continue\n",
    "        gray_image = np.squeeze(gray_image)\n",
    "        gray_image = gray_image.astype('uint8')\n",
    "\n",
    "        gray_face = gray_image\n",
    "\n",
    "        gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except:\n",
    "            print('exception ignored')\n",
    "\n",
    "        gray_face = preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        if 'fer' in layer_label:\n",
    "            gray_face = np.expand_dims(gray_face, 0)\n",
    "        if 'fer' not in layer_label:\n",
    "            gray_face = np.expand_dims(gray_face, -1)\n",
    "        dict_faces[str(image_path)]=emotion_classifier.predict(gray_face)\n",
    "    #     print(dict_faces)\n",
    "    #     with open('negative.txt', 'a') as file:\n",
    "    #         file.write(str(image_path) + ' ')\n",
    "    #         for prob in emotion_classifier.predict(gray_face)[0]:\n",
    "    #             file.write( str(prob) + ' ')\n",
    "    #         file.write('\\n')\n",
    "        i=i+1\n",
    "        sys.stdout.write(\"\\r%d%%\" % percentage)\n",
    "        sys.stdout.flush()\n",
    "    #     print(i)\n",
    "    print(j,' errors in', len(negative_faces),'faces')\n",
    "    return dict_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_faces_to_file(em_label, layer_label, val_or_train):\n",
    "    f_name=em_label+'_'+layer_label+'_'+val_or_train\n",
    "    file=open(f_name, 'wb')\n",
    "    pickle.dump(get_dict_faces('../imgs/'+val_or_train+'_crops/'+em_label+'/*', layer_label),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_dict_faces(layer_label):\n",
    "    val_or_train = 'train'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)\n",
    "    val_or_train = 'val'\n",
    "    save_dict_faces_to_file('negative', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('positive', layer_label, val_or_train)\n",
    "    save_dict_faces_to_file('neutral', layer_label, val_or_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.5/site-packages/keras/models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(1, 48, 48..., padding=\"valid\")`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(2, 2))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(1, 1))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(1, 1))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(1, 1))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(1, 1))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(data_format=\"channels_first\", padding=(1, 1))`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n",
      "/home/alexander/.local/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(alpha_initializer=\"zero\", weights=None)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%139  errors in 15401 faces\n",
      "99%64  errors in 9400 faces\n",
      "99%70  errors in 10046 faces\n",
      "99%69  errors in 8197 faces\n",
      "99%48  errors in 4995 faces\n",
      "86%"
     ]
    }
   ],
   "source": [
    "save_all_dict_faces(layer_label='fer_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('negative_pre_last_val.txt', 'wb')\n",
    "pickle.dump(dict_faces,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.5/site-packages/keras/models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(107, 87)\n",
      "(64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.96372315e-01,   7.60058492e-06,   2.60079920e-01,\n",
       "          5.83580477e-05,   4.94902551e-01,   1.58757064e-02,\n",
       "          3.27035487e-02]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size = l_model('prob')\n",
    "gray_image = load_image('../imgs/train_crops/negative/TrainNegative000045d4-642.jpgface0.bmp', grayscale=True)\n",
    "gray_image = np.squeeze(gray_image)\n",
    "gray_image = gray_image.astype('uint8')\n",
    "emotion_target_size=(64,64)\n",
    "print(emotion_target_size)\n",
    "gray_face = gray_image\n",
    "print(gray_face.shape)\n",
    "gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "print(gray_face.shape)\n",
    "try:\n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "except:\n",
    "    print('exception ignored')\n",
    "\n",
    "gray_face = preprocess_input(gray_face, True)\n",
    "gray_face = np.expand_dims(gray_face, 0)\n",
    "gray_face = np.expand_dims(gray_face, -1)\n",
    "# gray_face = gray_face[None,:]\n",
    "gray_face.shape\n",
    "emotion_classifier.predict(gray_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 64, 44, 44)        1664      \n",
      "_________________________________________________________________\n",
      "p_re_lu_22 (PReLU)           (None, 64, 44, 44)        123904    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 64, 48, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 64, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 22, 22)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_23 (PReLU)           (None, 64, 22, 22)        30976     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 64, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 22, 22)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_24 (PReLU)           (None, 64, 22, 22)        30976     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "p_re_lu_25 (PReLU)           (None, 128, 10, 10)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 128, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 10, 10)       147584    \n",
      "_________________________________________________________________\n",
      "p_re_lu_26 (PReLU)           (None, 128, 10, 10)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 128, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 128, 5, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              3277824   \n",
      "_________________________________________________________________\n",
      "p_re_lu_27 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "p_re_lu_28 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 7175      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 4,845,063\n",
      "Trainable params: 4,845,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emotion_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%139  errors in 15401 faces\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dict_faces_to_file('negative', 'emb', 'train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.5/site-packages/keras/models.py:288: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(107, 87)\n",
      "(64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.96372315e-01,   7.60058492e-06,   2.60079920e-01,\n",
       "          5.83580477e-05,   4.94902551e-01,   1.58757064e-02,\n",
       "          3.27035487e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size = l_model('prob')\n",
    "emotion_classifier.load_weights('../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5')\n",
    "gray_image = load_image('../imgs/train_crops/negative/TrainNegative000045d4-642.jpgface0.bmp', grayscale=True)\n",
    "gray_image = np.squeeze(gray_image)\n",
    "gray_image = gray_image.astype('uint8')\n",
    "emotion_target_size=(64,64)\n",
    "print(emotion_target_size)\n",
    "gray_face = gray_image\n",
    "print(gray_face.shape)\n",
    "gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "print(gray_face.shape)\n",
    "try:\n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "except:\n",
    "    print('exception ignored')\n",
    "\n",
    "gray_face = preprocess_input(gray_face, True)\n",
    "gray_face = np.expand_dims(gray_face, 0)\n",
    "gray_face = np.expand_dims(gray_face, -1)\n",
    "emotion_classifier.predict(gray_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(107, 87)\n",
      "(64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.96372315e-01,   7.60058492e-06,   2.60079920e-01,\n",
       "          5.83580477e-05,   4.94902551e-01,   1.58757064e-02,\n",
       "          3.27035487e-02]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_classifier, emotion_target_size = l_model('prob')\n",
    "# emotion_classifier.load_weights('../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5')\n",
    "gray_image = load_image('../imgs/train_crops/negative/TrainNegative000045d4-642.jpgface0.bmp', grayscale=True)\n",
    "gray_image = np.squeeze(gray_image)\n",
    "gray_image = gray_image.astype('uint8')\n",
    "emotion_target_size=(64,64)\n",
    "print(emotion_target_size)\n",
    "gray_face = gray_image\n",
    "print(gray_face.shape)\n",
    "gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "print(gray_face.shape)\n",
    "try:\n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "except:\n",
    "    print('exception ignored')\n",
    "\n",
    "gray_face = preprocess_input(gray_face, True)\n",
    "gray_face = np.expand_dims(gray_face, 0)\n",
    "gray_face = np.expand_dims(gray_face, -1)\n",
    "emotion_classifier.predict(gray_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier.load_weights('../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
